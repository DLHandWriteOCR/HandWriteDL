{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JImOAfeAbKY9",
        "outputId": "c45ff330-d34e-452d-8e84-d0d63f0f8e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (5,967 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123595 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "Collecting torch==1.13.1\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.14.1\n",
            "  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting torchaudio==0.13.1\n",
            "  Downloading torchaudio-0.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.12.2)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (71.0.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2024.7.4)\n",
            "Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-0.13.1-cp310-cp310-manylinux1_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.1+cu121\n",
            "    Uninstalling torchvision-0.18.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.3.1+cu121\n",
            "    Uninstalling torchaudio-2.3.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 torchaudio-0.13.1 torchvision-0.14.1\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install tesseract-ocr\n",
        "# !pip install torchvision==0.13.1\n",
        "!pip install opencv-python\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install pytesseract\n",
        "# !pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1\n",
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/clovaai/CRAFT-pytorch\n",
        "%cd CRAFT-pytorch\n",
        "\n",
        "import gdown\n",
        "\n",
        "# 파일 ID를 사용하여 다운로드 링크 생성\n",
        "file_id = '1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# 파일 다운로드\n",
        "output = 'craft_mlt_25k.pth'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "9FsUbjUobdJf",
        "outputId": "841a3aa9-1660-4fbd-8961-4da147e92ff7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CRAFT-pytorch'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Total 59 (delta 0), reused 0 (delta 0), pack-reused 59 (from 1)\u001b[K\n",
            "Receiving objects: 100% (59/59), 1.69 MiB | 15.74 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n",
            "/content/CRAFT-pytorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ\n",
            "To: /content/CRAFT-pytorch/craft_mlt_25k.pth\n",
            "100%|██████████| 83.2M/83.2M [00:00<00:00, 89.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'craft_mlt_25k.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from craft import CRAFT\n",
        "from craft_utils import getDetBoxes, adjustResultCoordinates\n",
        "from imgproc import loadImage, normalizeMeanVariance, resize_aspect_ratio\n",
        "import pytesseract"
      ],
      "metadata": {
        "id": "KY2SIr7Vbewf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab에 Google Drive 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEol6a3VnZ2M",
        "outputId": "6bc38268-eca6-41f5-e286-04183f5da078"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aLbFsmNK2Ie3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 모델 로드 함수\n",
        "\n",
        "def load_model():\n",
        "    model = CRAFT()\n",
        "    model.load_state_dict(torch.load('craft_mlt_25k.pth', map_location='cuda' if torch.cuda.is_available() else 'cpu'), strict=False)\n",
        "    model.eval()\n",
        "    return model\n",
        "# def load_model():\n",
        "#     model = CRAFT()  # CRAFT 모델 인스턴스 생성\n",
        "#     model.load_state_dict(torch.load('craft_mlt_25k.pth', map_location='cpu'))\n",
        "#     model.eval()  # 평가 모드로 설정\n",
        "#     return model\n",
        "\n",
        "# 5. 이미지 전처리 함수\n",
        "# def preprocess_image(image_path):\n",
        "#     image = loadImage(image_path)\n",
        "#     img_resized, target_ratio, size_heatmap = resize_aspect_ratio(image, 1280, interpolation=cv2.INTER_LINEAR, mag_ratio=1.5)\n",
        "#     img_normalized = normalizeMeanVariance(img_resized)\n",
        "#     img_normalized = torch.from_numpy(img_normalized).permute(2, 0, 1).unsqueeze(0)\n",
        "#     return img_normalized, size_heatmap, target_ratio\n",
        "\n",
        "# def preprocess_image(image_path):\n",
        "#     image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "#     _, image_bin = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "#     image_blurred = cv2.GaussianBlur(image_bin, (5, 5), 0)\n",
        "#     img_resized, target_ratio, size_heatmap = resize_aspect_ratio(image_blurred, 1280, interpolation=cv2.INTER_LINEAR, mag_ratio=1.5)\n",
        "#     img_normalized = normalizeMeanVariance(img_resized)\n",
        "#     img_normalized = torch.from_numpy(img_normalized).permute(2, 0, 1).unsqueeze(0)\n",
        "#     return img_normalized, size_heatmap, target_ratio\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    # 이미지를 그레이스케일로 읽기\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    # 이진화 적용\n",
        "    _, image_bin = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    # 가우시안 블러 적용\n",
        "    image_blurred = cv2.GaussianBlur(image_bin, (5, 5), 0)\n",
        "    # 이미지 크기 조정\n",
        "    img_resized, target_ratio, size_heatmap = resize_aspect_ratio(image_blurred, 1280, interpolation=cv2.INTER_LINEAR, mag_ratio=1.5)\n",
        "    # 채널을 추가하여 3채널 이미지로 변환\n",
        "    if len(img_resized.shape) == 2:  # 흑백 이미지\n",
        "        img_resized = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    img_normalized = normalizeMeanVariance(img_resized)\n",
        "    img_normalized = torch.from_numpy(img_normalized).permute(2, 0, 1).unsqueeze(0)\n",
        "    return img_normalized, size_heatmap, target_ratio\n",
        "\n",
        "\n",
        "# 6. 텍스트 박스 추출 함수 (모델 출력 확인 추가)\n",
        "# def extract_textboxes(image_path, model):\n",
        "#     img_normalized, size_heatmap, target_ratio = preprocess_image(image_path)\n",
        "#     with torch.no_grad():\n",
        "#         y, feature = model(img_normalized)\n",
        "\n",
        "#         # 모델 출력 확인\n",
        "#         print(f\"Model output (y): {type(y)}, shape: {y.shape}\")\n",
        "#         print(f\"Model output (feature): {type(feature)}, shape: {feature.shape}\")\n",
        "\n",
        "#     # y와 feature가 예상되는 형태인지 확인하고 이후 코드 수정\n",
        "#     boxes, polys = getDetBoxes(y, 0.7, 0.4, 0.4, True)\n",
        "#     boxes = adjustResultCoordinates(boxes, target_ratio)\n",
        "#     return boxes\n",
        "\n",
        "# 6. 텍스트 박스 추출 함수 (adjustResultCoordinates 수정)\n",
        "def extract_textboxes(image_path, model):\n",
        "    img_normalized, size_heatmap, target_ratio = preprocess_image(image_path)\n",
        "    with torch.no_grad():\n",
        "        y, _ = model(img_normalized)\n",
        "\n",
        "    # y 텐서에서 textmap과 linkmap 분리\n",
        "    y = y.squeeze(0).cpu().numpy()  # (height, width, 2)\n",
        "    textmap = y[:, :, 0]  # 텍스트 영역 맵\n",
        "    linkmap = y[:, :, 1]  # 링크 영역 맵\n",
        "\n",
        "    # # getDetBoxes를 호출할 때 textmap과 linkmap 전달\n",
        "    # boxes, polys = getDetBoxes(textmap, linkmap, 0.7, 0.4, 0.4, True)\n",
        "    # 예시: 임계값 조정\n",
        "    boxes, polys = getDetBoxes(textmap, linkmap, text_threshold=0.6, link_threshold=0.3, low_text=0.2, poly=False)\n",
        "\n",
        "    # adjustResultCoordinates를 호출할 때, 너비와 높이 비율 모두 전달\n",
        "    boxes = adjustResultCoordinates(boxes, ratio_w=target_ratio, ratio_h=target_ratio)\n",
        "    return boxes\n",
        "\n",
        "\n",
        "# 7. 결과 시각화 함수\n",
        "def visualize_results(image_path, boxes):\n",
        "    image = cv2.imread(image_path)\n",
        "    for box in boxes:\n",
        "        box = np.array(box).astype(np.int32).reshape((-1, 1, 2))\n",
        "        cv2.polylines(image, [box], isClosed=True, color=(0, 255, 0), thickness=2)\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 8. OCR로 텍스트 추출 함수\n",
        "def extract_text_from_boxes(image_path, boxes):\n",
        "    image = cv2.imread(image_path)\n",
        "    extracted_texts = []\n",
        "    for box in boxes:\n",
        "        # 각 박스의 좌표를 사용해 이미지에서 영역을 잘라내기\n",
        "        pts = np.array(box).reshape((-1, 2))\n",
        "        rect = cv2.boundingRect(pts)\n",
        "        x, y, w, h = rect\n",
        "        cropped_img = image[y:y+h, x:x+w]\n",
        "\n",
        "        # 잘라낸 이미지에서 텍스트 추출\n",
        "        text = pytesseract.image_to_string(cropped_img, lang='eng')\n",
        "        extracted_texts.append(text.strip())\n",
        "\n",
        "    return extracted_texts\n",
        "\n",
        "# imgproc.py의 resize_aspect_ratio 함수 수정\n",
        "def resize_aspect_ratio(img, square_size, interpolation=cv2.INTER_LINEAR, mag_ratio=1):\n",
        "    if len(img.shape) == 2:  # 흑백 이미지\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    height, width, channel = img.shape\n",
        "\n",
        "    # 이미지 크기 조정 비율 계산\n",
        "    img_w = int(width * mag_ratio)\n",
        "    img_h = int(height * mag_ratio)\n",
        "\n",
        "    # 크기 조정\n",
        "    img_resized = cv2.resize(img, (img_w, img_h), interpolation=interpolation)\n",
        "\n",
        "    # 패딩 추가\n",
        "    delta_w = max(square_size - img_w, 0)\n",
        "    delta_h = max(square_size - img_h, 0)\n",
        "\n",
        "    top = delta_h // 2\n",
        "    bottom = delta_h - top\n",
        "    left = delta_w // 2\n",
        "    right = delta_w - left\n",
        "\n",
        "    # 패딩을 추가하여 이미지 크기 맞추기\n",
        "    if img_resized.shape[2] == 3:  # 컬러 이미지\n",
        "        img_padded = cv2.copyMakeBorder(img_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(128, 128, 128))\n",
        "    else:  # 흑백 이미지\n",
        "        img_padded = cv2.copyMakeBorder(img_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=128)\n",
        "\n",
        "    return img_padded, img_w / width, img_h / height\n"
      ],
      "metadata": {
        "id": "AHUzDtFrc1Ld"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. 메인 실행 부분\n",
        "\n",
        "# 테스트를 위한 이미지 파일 설정\n",
        "test_png_file_path = '/content/drive/MyDrive/Colab Notebooks/DL project/data/image/P.Paper/O.Form/IMG_OCR_53_4PR_09180.png'\n",
        "\n",
        "# 메인 실행 부분에서 OCR 함수 호출\n",
        "if __name__ == '__main__':\n",
        "    model = load_model()\n",
        "    image_path = test_png_file_path  # 이미지 파일 경로를 지정하세요.\n",
        "\n",
        "    # 이미지가 정상적으로 업로드되었는지 확인\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Error: Could not load image from {image_path}. Please check the file path and permissions.\")\n",
        "    else:\n",
        "        boxes = extract_textboxes(image_path, model)\n",
        "        visualize_results(image_path, boxes)  # 시각화\n",
        "        texts = extract_text_from_boxes(image_path, boxes)  # 텍스트 추출\n",
        "        print(\"Extracted Texts:\")\n",
        "        for text in texts:\n",
        "            print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVNcwnSUc64I",
        "outputId": "795f14b9-3354-43e7-d78a-f34895690698"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and may be removed in the future. Please access them via the appropriate Weights Enum instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not load image from /content/drive/MyDrive/Colab Notebooks/DL project/data/image/P.Paper/O.Form/IMG_OCR_53_4PR_09180.png. Please check the file path and permissions.\n"
          ]
        }
      ]
    }
  ]
}