{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2107318b",
   "metadata": {},
   "source": [
    "# CRNN_OCR_Paper\n",
    "\n",
    "- 참고 사이트\n",
    "    - [[한글 OCR] CRNN Model 학습](https://velog.io/@shasha/%ED%95%9C%EA%B8%80-OCR-CRNN-Model-%ED%95%99%EC%8A%B5)\n",
    "    - [딥러닝을 활용한 한글문장 OCR 프로젝트](https://medium.com/@sunwoopark/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%ED%95%9C%EA%B8%80%EB%AC%B8%EC%9E%A5-ocr-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-hclt-2019-bb9d17622412)\n",
    "    - [[python] CRNN 한글 모델 학습하기(1) - AIhub 데이터셋](https://velog.io/@apphia39/python-CRNN-%ED%95%9C%EA%B8%80-%EB%AA%A8%EB%8D%B8-%ED%95%99%EC%8A%B5%ED%95%98%EA%B8%B0)\n",
    "    - [[#04] AI Hub 한국어 글자체 AI 이미지 데이터 전처리](https://cvml.tistory.com/21)\n",
    "    - [LMDB 형식 데이터셋이란? | 텍스트 인식 데이터셋 포맷](https://mvje.tistory.com/139)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13e363",
   "metadata": {},
   "source": [
    "## CRNN 구조\n",
    "- Convolution Layers : 입력 이미지로부터 feature 시퀀스 추출 ( -> CNNs )\n",
    "- Recurrent Layers : 각 프레임마다 라벨 예측 ( -> RNNs )\n",
    "- Transcriptional Layers : 프레임마다의 예측을 최종 라벨 시퀀스로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909bde6e",
   "metadata": {},
   "source": [
    "# 실제 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e97e1",
   "metadata": {},
   "source": [
    "## file 구조\n",
    "- 원본 파일 순서대로 사용할 것\n",
    "- json 파일 전처리 부분 재구성할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47c9350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:30:22.630848Z",
     "start_time": "2024-08-22T11:30:14.912788Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a5bb98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:30:22.661511Z",
     "start_time": "2024-08-22T11:30:22.636374Z"
    }
   },
   "outputs": [],
   "source": [
    "# JSON 파일 병합 함수\n",
    "def merge_json_files(input_dir, output_file):\n",
    "    merged_data = []\n",
    "    json_pattern = os.path.join(input_dir, '*.json')\n",
    "    file_list = glob.glob(json_pattern)\n",
    "    \n",
    "    for file in file_list:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            merged_data.append(data)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(merged_data, f, indent=4)\n",
    "\n",
    "# 입력 디렉토리와 출력 파일 경로 설정\n",
    "\n",
    "TL_path = 'data/OCR_Bulk/TL/P.Paper/'\n",
    "VL_path = 'data/OCR_Bulk/VL/P.Paper/'\n",
    "\n",
    "folders = ['O.Form/', 'R.Free/']\n",
    "\n",
    "def FileList(path, folders):\n",
    "    \n",
    "    for folder in folders:\n",
    "        input_directory = path + folder\n",
    "\n",
    "        output_file = 'merged_labels_paper_Train_' + folder[:1] + '.json'\n",
    "\n",
    "        # JSON 파일 병합 실행\n",
    "        merge_json_files(input_directory, output_file)\n",
    "        print(f\"Merged JSON data written to '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d6b7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T10:35:20.706983Z",
     "start_time": "2024-08-22T10:35:20.688907Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FileList(VL_path, folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da7fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T10:35:20.722003Z",
     "start_time": "2024-08-22T10:35:20.708977Z"
    }
   },
   "outputs": [],
   "source": [
    "# FileList(TL_path, folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53029ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:30:28.881439Z",
     "start_time": "2024-08-22T11:30:22.665898Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# JSON 파일 로드 함수\n",
    "def load_json(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "def preprocess_image(image_path, bounding_box):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     print(image)\n",
    "    x, y, w, h = bounding_box\n",
    "#     print(x, y, w, h)\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "#     print('crop')\n",
    "    resized_image = cv2.resize(cropped_image, (128, 32))  # CRNN 입력 크기에 맞게 조정\n",
    "    normalized_image = resized_image / 255.0\n",
    "    return normalized_image\n",
    "\n",
    "# JSON 파일 경로\n",
    "# json_path = merged_labels_paper_Train_R.json\n",
    "json_path = 'merged_labels_paper_Train_O.json'\n",
    "data = load_json(json_path)\n",
    "\n",
    "# 각 단어의 바운딩 박스와 텍스트 정보\n",
    "words_info = data[0]['bbox']\n",
    "\n",
    "# 이미지 경로\n",
    "image_path = 'data/OCR_Bulk/VS/P.Paper/O.Form/' + data[0]['Images']['identifier'] + '.' + data[0]['Images']['type']\n",
    "\n",
    "# 전처리된 이미지 리스트\n",
    "processed_images = []\n",
    "for word_info in words_info:\n",
    "\n",
    "    # x, y, w, h\n",
    "    bounding_box = [word_info['x'][0], \n",
    "                    word_info['y'][0],\n",
    "                    word_info['x'][2] - word_info['x'][0], \n",
    "                    word_info['y'][1] - word_info['y'][0]\n",
    "                   ]\n",
    "    processed_image = preprocess_image(image_path, bounding_box)\n",
    "    processed_images.append(processed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3a15c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T10:35:26.406163Z",
     "start_time": "2024-08-22T10:35:24.226053Z"
    }
   },
   "outputs": [],
   "source": [
    "# def preprocess_image(image_path, bounding_box):\n",
    "#     image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "# #     cv2.imshow('rgb_image', image)\n",
    "# #     print(image)\n",
    "#     x, y, w, h = bounding_box\n",
    "# #     print(x, y, w, h)\n",
    "#     cropped_image = image[y:y+h, x:x+w]\n",
    "# #     print('crop')\n",
    "#     resized_image = cv2.resize(cropped_image, (128, 32))  # CRNN 입력 크기에 맞게 조정\n",
    "#     normalized_image = resized_image / 255.0\n",
    "#     return normalized_image\n",
    "\n",
    "# for word_info in words_info:\n",
    "\n",
    "#     # x, y, w, h\n",
    "#     bounding_box = [word_info['x'][0], \n",
    "#                     word_info['y'][0],\n",
    "#                     word_info['x'][2] - word_info['x'][0], \n",
    "#                     word_info['y'][1] - word_info['y'][0]\n",
    "#                    ]\n",
    "#     processed_image = preprocess_image(image_path, bounding_box)\n",
    "#     processed_images.append(processed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4724561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T10:35:26.423986Z",
     "start_time": "2024-08-22T10:35:26.408034Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 각 단어의 바운딩 박스와 텍스트 정보\n",
    "# words_info = data[0]['bbox']\n",
    "\n",
    "# # 이미지 경로\n",
    "# image_path = data[0]['Images']['identifier'] + '.' + data[0]['Images']['type']\n",
    "\n",
    "# # 전처리된 이미지 리스트\n",
    "# processed_images = []\n",
    "# for word_info in words_info:\n",
    "\n",
    "#     bounding_box = [word_info['x'][0], \n",
    "#                     word_info['y'][0],\n",
    "#                     word_info['x'][2] - word_info['x'][0], \n",
    "#                     word_info['y'][1] - word_info['y'][0]\n",
    "#                    ]\n",
    "#     print(bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987f2ff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:30:29.937678Z",
     "start_time": "2024-08-22T11:30:28.884431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 128, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 128, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 64, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 32, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 256, 64)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 256, 256)          197632    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256, 2350)         603950    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 820398 (3.13 MB)\n",
      "Trainable params: 820398 (3.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CTC 디코딩 함수\n",
    "def ctc_decode(predictions, charset):\n",
    "    decoded = K.ctc_decode(predictions, input_length=np.ones(predictions.shape[0]) * predictions.shape[1])[0][0]\n",
    "    decoded_text = K.get_value(decoded)\n",
    "    return ''.join([charset[i] for i in decoded_text if i != -1])\n",
    "\n",
    "# CRNN 모델 정의 (간단한 예제)\n",
    "# Conv-Pool layer 갯수 = 찾을 특성의 갯수\n",
    "# padding: 사이즈 유지를 위해 conv전에 0을 모서리에 추가함\n",
    "# drop out: 일부러 정보를 누락, 중간 노드를 꺼서 과적합을 방지하는데에 사용\n",
    "    # 응용력을 주는 것\n",
    "def build_crnn_model(input_shape, num_classes):\n",
    "    input_layer = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Reshape((-1, x.shape[-1]))(x)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=x)\n",
    "    return model\n",
    "\n",
    "# 모델 입력 크기와 클래스 수 정의\n",
    "input_shape = (32, 128, 1)\n",
    "num_classes = 2350  # 예: 한글 음절 수\n",
    "\n",
    "# 모델 빌드\n",
    "model = build_crnn_model(input_shape, num_classes)\n",
    "\n",
    "# 모델 요약 출력\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7425e",
   "metadata": {},
   "source": [
    "charset 값으로 들어가야 하는 실제 한글 음절 셋은 CRNN 모델이 예측한 인덱스를 실제 한글 문자로 변환하기 위한 문자 집합입니다. 한글 음절 셋은 모델이 인식할 수 있는 모든 한글 음절을 포함해야 합니다. 예를 들어, 한글 음절은 ‘가’, ‘나’, ‘다’, ‘라’ 등으로 구성됩니다.\n",
    "\n",
    "- Input Layer:\n",
    "    - input_1 (InputLayer): 입력 데이터의 형태는 (None, 32, 128, 1)입니다. 여기서 None은 배치 크기를 의미하며, (32, 128, 1)은 이미지의 높이, 너비, 채널 수를 나타냅니다.\n",
    "- Conv2D Layer:\n",
    "    - conv2d (Conv2D): 첫 번째 합성곱 층으로, 32개의 필터를 사용하여 (3, 3) 크기의 커널을 적용합니다. 출력 형태는 (None, 32, 128, 32)이며, 파라미터 수는 320입니다.\n",
    "    - max_pooling2d (MaxPooling2D): 첫 번째 풀링 층으로, (2, 2) 크기의 풀링을 적용합니다. 출력 형태는 (None, 16, 64, 32)입니다.\n",
    "- Conv2D Layer:\n",
    "    - conv2d_1 (Conv2D): 두 번째 합성곱 층으로, 64개의 필터를 사용하여 (3, 3) 크기의 커널을 적용합니다. 출력 형태는 (None, 16, 64, 64)이며, 파라미터 수는 18,496입니다.\n",
    "    - max_pooling2d_1 (MaxPooling2D): 두 번째 풀링 층으로, (2, 2) 크기의 풀링을 적용합니다. 출력 형태는 (None, 8, 32, 64)입니다.\n",
    "- Reshape Layer:\n",
    "    - reshape (Reshape): 데이터를 (None, 256, 64) 형태로 재구성합니다. 여기서 256은 타임스텝 수, 64는 특징 맵의 수입니다.\n",
    "- Bidirectional LSTM Layer:\n",
    "    - bidirectional (Bidirectional): 양방향 LSTM 층으로, 각 방향에 128개의 유닛을 사용합니다. 출력 형태는 (None, 256, 256)이며, 파라미터 수는 197,632입니다.\n",
    "- Dense Layer:\n",
    "    - dense (Dense): 출력 층으로, 2350개의 클래스(한글 음절 수)를 예측합니다. 출력 형태는 (None, 256, 2350)이며, 파라미터 수는 603,950입니다.\n",
    "- 총 파라미터 수\n",
    "    - Total params: 820,398\n",
    "    - Trainable params: 820,398\n",
    "    - Non-trainable params: 0\n",
    "- 이 요약 결과는 모델의 각 층이 어떻게 구성되어 있는지, 각 층의 출력 형태와 파라미터 수를 보여줍니다. 이를 통해 모델의 복잡도와 메모리 요구 사항을 파악할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d9e862e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:30:34.181460Z",
     "start_time": "2024-08-22T11:30:29.943612Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 수행\n",
      "예측값 선언\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "디코딩\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# CTC 디코딩을 통해 실제 텍스트 판독\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m디코딩\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m predicted_text \u001b[38;5;241m=\u001b[39m \u001b[43mctc_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m, in \u001b[0;36mctc_decode\u001b[1;34m(predictions, charset)\u001b[0m\n\u001b[0;32m      3\u001b[0m decoded \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mctc_decode(predictions, input_length\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m decoded_text \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mget_value(decoded)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([charset[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m decoded_text \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m decoded \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mctc_decode(predictions, input_length\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m decoded_text \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mget_value(decoded)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([charset[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m decoded_text \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m])\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# 예측 수행 및 CTC 디코딩\n",
    "# charset = '가나다라마바사아자차카타파하'  # 예시 문자셋 (실제 한글 음절 셋으로 대체 필요)\n",
    "\n",
    "# 한글 음절 셋 생성 코드\n",
    "def generate_hangul_syllables():\n",
    "    hangul_syllables = []\n",
    "    for cho in range(0x1100, 0x1113):  # 초성 (19자)\n",
    "        for jung in range(0x1161, 0x1176):  # 중성 (21자)\n",
    "            for jong in range(0x11A8, 0x11C3):  # 종성 (27자)\n",
    "                syllable = chr(0xAC00 + (cho - 0x1100) * 21 * 28 + (jung - 0x1161) * 28 + (jong - 0x11A7))\n",
    "                hangul_syllables.append(syllable)\n",
    "    return hangul_syllables\n",
    "\n",
    "# 한글 음절 셋 생성\n",
    "hangul_syllables = generate_hangul_syllables()\n",
    "\n",
    "# 생성된 한글 음절 셋 출력 (일부 예시)\n",
    "# print(hangul_syllables[:100])  # 처음 100개의 음절 출력\n",
    "\n",
    "# 한문, 영어, 특수문자는 일단 제외함\n",
    "\n",
    "charset = hangul_syllables\n",
    "\n",
    "for processed_image in processed_images:\n",
    "    print('예측 수행')\n",
    "    processed_image = np.expand_dims(processed_image, axis=-1)  # 채널 차원 추가\n",
    "    processed_image = np.expand_dims(processed_image, axis=0)  # 배치 차원 추가\n",
    "    print('예측값 선언')\n",
    "    predictions = model.predict(processed_image)\n",
    "    \n",
    "    # CTC 디코딩을 통해 실제 텍스트 판독\n",
    "    print('디코딩')\n",
    "    predicted_text = ctc_decode(predictions, charset)\n",
    "    print(f\"Predicted text: {predicted_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48efbd45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:30:53.029332Z",
     "start_time": "2024-08-22T11:30:53.011162Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00043285, 0.00042642, 0.00042254, ..., 0.00041453,\n",
       "         0.00043274, 0.00042946],\n",
       "        [0.00043297, 0.00042556, 0.00042413, ..., 0.00041413,\n",
       "         0.00043265, 0.00042948],\n",
       "        [0.00043272, 0.00042511, 0.00042492, ..., 0.00041373,\n",
       "         0.00043256, 0.00042947],\n",
       "        ...,\n",
       "        [0.00042761, 0.00042256, 0.00043273, ..., 0.00041754,\n",
       "         0.00042574, 0.00042679],\n",
       "        [0.00042666, 0.00042218, 0.000433  , ..., 0.0004184 ,\n",
       "         0.0004248 , 0.00042649],\n",
       "        [0.00042467, 0.00042201, 0.0004336 , ..., 0.00041994,\n",
       "         0.00042275, 0.00042562]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f1906b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T11:31:40.820769Z",
     "start_time": "2024-08-22T11:31:40.808345Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.99215686],\n",
       "         [0.99215686],\n",
       "         [0.99215686]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[0.99607843],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.99607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         ...,\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.99607843]],\n",
       "\n",
       "        [[0.99215686],\n",
       "         [0.99215686],\n",
       "         [0.99215686],\n",
       "         ...,\n",
       "         [0.99607843],\n",
       "         [0.99607843],\n",
       "         [0.99607843]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85136c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "ds_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
